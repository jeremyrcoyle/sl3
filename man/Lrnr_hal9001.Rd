% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Lrnr_hal9001.R
\docType{class}
\name{Lrnr_hal9001}
\alias{Lrnr_hal9001}
\title{Computationally Efficient hal9001}
\format{\code{\link{R6Class}} object.}
\usage{
Lrnr_hal9001
}
\value{
Learner object with methods for training and prediction. See \code{\link{Lrnr_base}} for documentation on learners.
}
\description{
The procedure uses a custom C++ implementation to generate a design
matrix (consisting of basis functions corresponding to covariates and
interactions of covariates) and remove duplicate columns of indicators. The
LASSO regression is fit to this (usually) very wide matrix using either a
custom implementation (based on the \code{origami} package) or by a call to
\code{cv.glmnet} from the \code{glmnet} package.
}
\section{Parameters}{

\describe{
\item{\code{degrees="degrees"}}{ The highest order of interaction terms for which the basis functions ought to be generated. The default (\code{NULL}) corresponds to generating basis functions for the full dimensionality of the input matrix.
}
\item{\code{fit_type="fit_type"}}{ The specific routine to be called when fitting the LASSO regression in a cross-validated manner. Choosing the \code{glmnet} option will result in a call to \code{cv.glmnet} while \code{origami} will produce a (faster) call to a custom routine based on the \code{origami} package.
}
\item{\code{n_folds="n_folds"}}{ Integer for the number of folds to be used when splitting the data for cross-validation. This defaults to 10 as this is the convention for v-fold cross-validation.
}
\item{\code{use_min="use_min"}}{ Determines which lambda is selected from \code{cv.glmnet}. \code{TRUE} corresponds to \code{"lambda.min"} and \code{FALSE} corresponds to \code{"lambda.1se"}.
}
\item{\code{...}}{ Other parameters passed directly to \code{\link[hal9001]{fit_hal}}. See its documentation for details.
}
}
}

\seealso{
Other Learners: \code{\link{Custom_chain}},
  \code{\link{Lrnr_HarmonicReg}}, \code{\link{Lrnr_arima}},
  \code{\link{Lrnr_base}}, \code{\link{Lrnr_bilstm}},
  \code{\link{Lrnr_condensier}}, \code{\link{Lrnr_cv}},
  \code{\link{Lrnr_define_interactions}},
  \code{\link{Lrnr_expSmooth}},
  \code{\link{Lrnr_glm_fast}}, \code{\link{Lrnr_glmnet}},
  \code{\link{Lrnr_glm}}, \code{\link{Lrnr_h2o_grid}},
  \code{\link{Lrnr_independent_binomial}},
  \code{\link{Lrnr_lstm}}, \code{\link{Lrnr_mean}},
  \code{\link{Lrnr_nnls}}, \code{\link{Lrnr_optim}},
  \code{\link{Lrnr_pkg_SuperLearner}},
  \code{\link{Lrnr_randomForest}},
  \code{\link{Lrnr_rugarch}}, \code{\link{Lrnr_sl}},
  \code{\link{Lrnr_solnp_density}},
  \code{\link{Lrnr_solnp}},
  \code{\link{Lrnr_subset_covariates}},
  \code{\link{Lrnr_tsDyn}}, \code{\link{Lrnr_xgboost}},
  \code{\link{Pipeline}}, \code{\link{Stack}},
  \code{\link{define_h2o_X}},
  \code{\link{undocumented_learner}}
}
\keyword{data}
